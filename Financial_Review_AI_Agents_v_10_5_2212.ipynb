{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kvnhooman/AAI520_Final-Project_Group5/blob/tommy-dev-1/Financial_Review_AI_Agents_v_10_5_2212.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z34tfGYWXK7X"
      },
      "source": [
        "# Title\n",
        "**Group 5**\n",
        "\n",
        "Final Project\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pss-SJpmYEdY"
      },
      "source": [
        "___\n",
        "## Outline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au9v6SfkXl5p"
      },
      "source": [
        "**Core Agent Functions**\n",
        "\n",
        "* Planning Agent: Plans research steps for stock analysis\n",
        "\n",
        "\n",
        "* Tool Use Agent: Integrates APIs (Yahoo Finance, SEC EDGAR, News APIs)\n",
        "\n",
        "\n",
        "* Self-Reflection Agent: Evaluates output quality and iterates\n",
        "\n",
        "\n",
        "* Learning Agent: Maintains memory across analysis runs\n",
        "\n",
        "\n",
        "**Workflow Patterns**\n",
        "* Prompt Chaining: News ingestion → preprocessing → classification → extraction → summarization\n",
        "\n",
        "\n",
        "* Routing: Directs content to specialist analyzers (earnings, news, market)\n",
        "\n",
        "\n",
        "* Evaluator-Optimizer: Generates analysis → evaluates quality → refines using feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "p_jPSJnIXKke",
        "outputId": "130c2352-468c-49f9-81a3-34bcbfd13d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.77)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filetype<2,>=1.2 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Downloading langchain_openai-0.3.34-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-openai, google-ai-generativelanguage, langchain-google-genai, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.7.0 langchain-community-0.3.30 langchain-google-genai-2.1.12 langchain-openai-0.3.34 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "requests"
                ]
              },
              "id": "971c97f6f33f4cd7893cb393083f101b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.1.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.183.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.1.0-py3-none-any.whl (964 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m964.9/964.9 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, google-ai-generativelanguage\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.7.0\n",
            "    Uninstalling google-ai-generativelanguage-0.7.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15 openai-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4d06a02322cd4a5aaf51d516e46bbcd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (8.3.0)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-8.1.1 primp-0.15.0\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.6.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.0)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Collecting lxml>=6.0.0 (from ddgs)\n",
            "  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
            "Downloading ddgs-9.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, lxml, ddgs\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.4.0\n",
            "    Uninstalling lxml-5.4.0:\n",
            "      Successfully uninstalled lxml-5.4.0\n",
            "Successfully installed ddgs-9.6.0 lxml-6.0.2 socksio-1.0.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.77)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.8-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.8 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.10.0\n",
            "Collecting restrictedpython\n",
            "  Downloading RestrictedPython-8.0-py3-none-any.whl.metadata (14 kB)\n",
            "Downloading RestrictedPython-8.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: restrictedpython\n",
            "Successfully installed restrictedpython-8.0\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=b6ee44a7a3c3123c8e1e5d8e42235b7aa986c5e7d3941c6ff3e2aaa21d4e8548\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install dependencis\n",
        "# Attribution: Geek for Geeks tutorial - https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/\n",
        "\n",
        "# -- CORE LANGCHAIN AND PLUGINS --\n",
        "!pip install -U langchain langchain-openai langchain-community langchain-google-genai\n",
        "\n",
        "# -- LARGE MODEL PROVIDERS/SKILL ADAPTERS --\n",
        "!pip install -U google-generativeai huggingface_hub openai\n",
        "\n",
        "# -- COMMON TOOLING AND UTILITIES --\n",
        "!pip install -U python-dotenv yfinance duckduckgo-search\n",
        "\n",
        "# -- DUCKDUCKGO SEARCH API WRAPPER --\n",
        "!pip install -U ddgs\n",
        "\n",
        "# -- OPTIONAL: For advanced memory (semantic search/vector db) --\n",
        "!pip install -U faiss-cpu  # For in-memory vector DBs (Lightweight)\n",
        "# If you want persistent/production memory, add chromadb or qdrant-client\n",
        "\n",
        "# -- Install LangGraph for advanced agent orchestration --\n",
        "!pip install -U langgraph\n",
        "\n",
        "# -- (OPTIONAL) For running Python tool actions securely --\n",
        "!pip install -U restrictedpython\n",
        "\n",
        "\n",
        "!pip install wikipedia\n",
        "\n",
        "# Restart the runtime after running this cell if prompted!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zeCeqrXeXdDA"
      },
      "outputs": [],
      "source": [
        "#Import key libraries\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents import create_react_agent, AgentExecutor, initialize_agent, Tool, AgentType\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.tools import tool  # newer import for @tool decorator\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "#Correct import path for YahooFinanceAPI\n",
        "import yfinance as yf\n",
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "#Memory\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SVdqL2i_ZTB0"
      },
      "outputs": [],
      "source": [
        "#Set up LLM API Calls\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_key = userdata.get('GEMINI')\n",
        "hf_key = userdata.get('HF_TOKEN')\n",
        "openai_key = userdata.get('OPENAI')\n",
        "fin_news = userdata.get('FIN_API_KEY')\n",
        "tavily_key = userdata.get('TAVILY_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jlClLEzOAxjy"
      },
      "outputs": [],
      "source": [
        "# Setup Gemini to use in Agents\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm_gemini = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    google_api_key=gemini_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YLzJeOnGPgW",
        "outputId": "62d34dec-548a-4ec8-e1b4-b944712e52dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API Response: content='GoogleAPI-success-check' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--426b0b71-d3e5-49c8-9080-6df4542d314a-0'\n"
          ]
        }
      ],
      "source": [
        "# Test if Gemini LLM is reachable\n",
        "try:\n",
        "    response = llm_gemini.invoke(\"Say 'GoogleAPI-success-check'\")\n",
        "    print(\"Gemini API Response:\", response)\n",
        "except Exception as e:\n",
        "    print(\"Error reaching Gemini API:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m95A2uEwHt4O"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm_openai = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",  # \"gpt-3.5-turbo\", \"gpt-4-mini\", \"gpt-5-mini\" ...\n",
        "    openai_api_key=openai_key,  # Your OpenAI API key\n",
        "    temperature=0.0             # (optional) set as needed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu6ALnCIHxr9",
        "outputId": "1ea91c5b-7f8c-42d8-bf82-5e9841009ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learns patterns from data to make predictions.\n"
          ]
        }
      ],
      "source": [
        "#Test OpenAI API\n",
        "#response = llm_openai.invoke(\"Explain how neural networks work in 10 words or less.\")\n",
        "response = llm_gemini.invoke(\"Explain how neural networks work in 10 words or less.\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input Context Extractor Function"
      ],
      "metadata": {
        "id": "2iVDzqg0gaPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_initial_state(user_input):\n",
        "    return {\n",
        "        \"user_input\": user_input,\n",
        "        \"symbol\": extract_symbol_simple(user_input),  # Simple regex\n",
        "        \"date\": datetime.now().date().isoformat(),\n",
        "        \"tools_output\": \"\",\n",
        "        \"evaluation_output\": \"\",\n",
        "        \"final_output\": \"\"\n",
        "    }"
      ],
      "metadata": {
        "id": "Fx1Z4opM5ihs"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_symbol_simple(text):\n",
        "    \"\"\"Just grab first 2-5 char uppercase word\"\"\"\n",
        "    match = re.search(r\"\\b([A-Z]{2,5})\\b\", text)\n",
        "    return match.group(1) if match else \"UNKNOWN\""
      ],
      "metadata": {
        "id": "Z7VDvP205pgU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_context(user_input):\n",
        "    \"\"\"\n",
        "    Extracts key context fields from user input for agent API use.\n",
        "\n",
        "    Fields:\n",
        "      - input (str): raw user text\n",
        "      - symbol (str): detected uppercase ticker (2-5 chars)\n",
        "      - company_name (str): placeholder for future NLP extraction\n",
        "      - date (str): today's date in ISO format (YYYY-MM-DD)\n",
        "      - agent_scratchpad (str): empty, reserved for intermediate agent notes\n",
        "      - research_notes (str): empty, reserved for additional notes\n",
        "    \"\"\"\n",
        "    # Extract uppercase ticker symbol (2-5 chars)\n",
        "    match = re.search(r\"\\b([A-Z]{2,5})\\b\", user_input)\n",
        "    symbol = match.group(1) if match else \"\"\n",
        "\n",
        "    # Placeholder for company name extraction\n",
        "    company_name = \"\"  # Optional: implement NER for this\n",
        "\n",
        "    # Today's date in ISO format\n",
        "    today = datetime.now().date().isoformat()\n",
        "\n",
        "    # Build context dictionary\n",
        "    context = {\n",
        "        'input': user_input,\n",
        "        'symbol': symbol,\n",
        "        'company_name': company_name,\n",
        "        'date': today,\n",
        "        'agent_scratchpad': '',\n",
        "        'research_notes': ''\n",
        "    }\n",
        "    return context"
      ],
      "metadata": {
        "id": "AfRwYIsOghzz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input extraction output\n",
        "context = extract_context(user_input)\n",
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJQEJBhC3M3E",
        "outputId": "316ab48f-0ac9-44ab-ef3f-437ab6e7f60d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Analyze the AAPL stock', 'symbol': 'AAPL', 'company_name': '', 'date': '2025-10-06', 'agent_scratchpad': '', 'research_notes': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7IzZtQ0i_p0"
      },
      "source": [
        "## Tool Agent\n",
        "Integrates APIs (Yahoo Finance, SEC EDGAR, News APIs)\n",
        "\n",
        "List of Tools:\n",
        "- Web Search\n",
        "- API call - Yahoo Finance\n",
        "- to be updated..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz8YEnt9jfua"
      },
      "source": [
        "### Tool Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdaDsWKejACq"
      },
      "outputs": [],
      "source": [
        "#For potential future use\n",
        "#from fredapi import Fred\n",
        "##fred = Fred(api_key='YOUR_API_KEY')\n",
        "#data = fred.get_series('SP500')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OFCPTCNfkIit"
      },
      "outputs": [],
      "source": [
        "#Yahoo Finance Tool\n",
        "def get_stock_price(ticker: str) -> str:\n",
        "    try:\n",
        "        price = yf.Ticker(ticker).info['regularMarketPrice']\n",
        "        return f\"{ticker} price is {price}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching price for {ticker}: {e}\"\n",
        "\n",
        "yahoo_api_tool = Tool(\n",
        "    name=\"YahooFinanceAPI\",\n",
        "    func=get_stock_price,\n",
        "    description=\"Queries Yahoo Finance for stock price and financials\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "c5R0boxlkaL8"
      },
      "outputs": [],
      "source": [
        "#SEC Filings\n",
        "def get_sec_filings(ticker: str) -> str:\n",
        "    cik_url = \"https://www.sec.gov/files/company_tickers.json\"\n",
        "    headers = {\"User-Agent\": \"tpool@sandiego.edu\"}  # Use your real email!\n",
        "    cik_resp = requests.get(cik_url, headers=headers)\n",
        "    print(f\"cik_resp: {cik_resp.status_code}, {cik_resp.text[:100]}\")\n",
        "\n",
        "    if cik_resp.status_code != 200:\n",
        "        return f\"SEC.gov rejected our request: {cik_resp.status_code}\\n{cik_resp.text[:200]}\"\n",
        "\n",
        "    try:\n",
        "        cik_data = cik_resp.json()\n",
        "        cik_lookup = {item['ticker']: item['cik_str'] for item in cik_data.values()}\n",
        "        cik = cik_lookup.get(ticker.upper())\n",
        "    except Exception as e:\n",
        "        return f\"Error parsing CIK data: {e}\"\n",
        "\n",
        "    if not cik:\n",
        "        return f\"CIK for {ticker} not found.\"\n",
        "\n",
        "    filings_url = f\"https://data.sec.gov/submissions/CIK{cik:0>10}.json\"\n",
        "    filings_resp = requests.get(filings_url, headers=headers)\n",
        "\n",
        "    try:\n",
        "        data = filings_resp.json() if filings_resp.status_code == 200 else {}\n",
        "        filings = data.get('filings', {}).get('recent', {})\n",
        "        if filings:\n",
        "            forms = filings.get('form', [])[:3]\n",
        "            filing_dates = filings.get('filingDate', [])[:3] #If successful, get filing dates\n",
        "            filing_links = filings.get('primaryDocument', [])[:3] #Also get three primary documents for agent\n",
        "            result = []\n",
        "            for f, d, l in zip(forms, filing_dates, filing_links):\n",
        "                result.append(f\"{f} on {d}: {l}\")\n",
        "            return f\"Latest filings for {ticker}:\\n\" + \"\\n\".join(result)\n",
        "        else:\n",
        "            return f\"No filings found for {ticker}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading filings for {ticker}: {e}\"\n",
        "\n",
        "\n",
        "sec_api_tool = Tool(\n",
        "    name=\"SECEDGARAPI\",\n",
        "    func=get_sec_filings,\n",
        "    description=\"Retrieves SEC filings on stock symbol\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For debugging\n",
        "#print(get_sec_filings(\"TSLA\"))"
      ],
      "metadata": {
        "id": "IdTf_zXh_wd0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Dxj27nAMk1VE"
      },
      "outputs": [],
      "source": [
        "def get_fin_news(symbol: str) -> str:\n",
        "    api_key = fin_news\n",
        "    url = \"https://newsapi.org/v2/everything\"\n",
        "    params = {\n",
        "        \"q\": symbol,\n",
        "        \"apiKey\": api_key,\n",
        "        \"sortBy\": \"publishedAt\",\n",
        "        \"language\": \"en\"\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        return f\"API error {response.status_code}: {response.text[:200]}\"\n",
        "    data = response.json()\n",
        "    articles = data.get(\"articles\", [])\n",
        "    if not articles:\n",
        "        return f\"No news found for {symbol}. Full message: {data.get('message', '')}\"\n",
        "    return \"\\n\".join([a[\"description\"] or a[\"title\"] for a in articles[:3]])\n",
        "\n",
        "\n",
        "news_api_tool = Tool(\n",
        "    name=\"NewsAPI\",\n",
        "    func=get_fin_news,  #Assumes you've defined this class\n",
        "    description=\"Finds recent financial news on stock symbol\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "082Rks6EmO0V"
      },
      "outputs": [],
      "source": [
        "def get_fin_news_tavily(symbol: str) -> str:\n",
        "    api_key = tavily_key\n",
        "    url = \"https://api.tavily.com/search\"\n",
        "    # You can optimize the query for financial news by including keywords:\n",
        "    query = f\"{symbol} financial news\"\n",
        "    payload = {\n",
        "        \"query\": query,\n",
        "        \"api_key\": api_key,\n",
        "        \"max_results\": 3,  # You can set number of results as you prefer\n",
        "    }\n",
        "    response = requests.post(url, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        results = data.get(\"results\", [])\n",
        "        # Each result contains title, link, snippet, etc.\n",
        "        return \"\\n\".join([r.get(\"title\", \"No title\") for r in results]) if results else \"No news found.\"\n",
        "    else:\n",
        "        return f\"Error from Tavily: {response.status_code} {response.text}\"\n",
        "\n",
        "tavily_news_tool = Tool(\n",
        "    name=\"TavilyNewsSearch\",\n",
        "    func=get_fin_news_tavily,\n",
        "    description=\"Searches web for recent financial news about a stock symbol using Tavily API.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wikipedia Search Tool\n",
        "from wikipedia import summary\n",
        "\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    # If query looks like a ticker (e.g., all caps, 2-5 chars), get company name\n",
        "    if query.isupper() and 2 <= len(query) <= 5:\n",
        "        company_name = get_company_name(query)\n",
        "        search_term = f\"{company_name} stock\"\n",
        "    else:\n",
        "        search_term = query\n",
        "\n",
        "    try:\n",
        "        return summary(search_term, sentences=2)\n",
        "    except Exception:\n",
        "        # Fallback, try just company name (without \"stock\")\n",
        "        if search_term != query:\n",
        "            try:\n",
        "                return summary(company_name, sentences=2)\n",
        "            except Exception:\n",
        "                pass\n",
        "        return \"I couldn't find any information on that.\"\n",
        "\n",
        "wikipedia_tool = Tool(\n",
        "    name=\"WikipediaSearch\",\n",
        "    func=search_wikipedia,\n",
        "    description=\"Searches Wikipedia and returns a summary for a stock symbol or company name.\"\n",
        ")"
      ],
      "metadata": {
        "id": "DQE5ECwx8iHQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "class HuggingFaceSentimentTool:\n",
        "    def __init__(self):\n",
        "        self.classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "    def analyze(self, text):\n",
        "        result = self.classifier(text)[0]\n",
        "        # result['label'] is 'POSITIVE' or 'NEGATIVE'\n",
        "        return 1 if result['label'] == \"POSITIVE\" else -1\n",
        "\n",
        "sentiment_api_tool = Tool (\n",
        "    name=\"HuggingFaceSentiment\",\n",
        "    func=HuggingFaceSentimentTool().analyze,\n",
        "    description=\"Analyzes sentiment of text using HuggingFace\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "047e4f5bb8634f1ea706e06f376fef7b",
            "bc143309bac14465b28197b3d7216b88",
            "ae36bf92882b4b898c4e790f6816644f",
            "c270447b325a4669b7206c5277825728",
            "0924a3a6bb6745ed832196b5ac1735c2",
            "20c8c80896584df68ebc192d2d270d0f",
            "93704669bbc04d16b559aaa7ca038b85",
            "151fadcd660b4ba6aa4b689ea0911a64",
            "61e0505a3457467ba2ab7b76c0d614f0",
            "c028f7bbbf77493dbc5161390077f320",
            "2bf0fbcc900c47629b595382255d4d1b",
            "9a92aa0db5a346329c02079b2ec30501",
            "73aa0b6b4ada48a98c4c88730aa70452",
            "f1b7a0cbd27b4bc5b5a71808e6f9c777",
            "65945c21c7d34dcbb58e66ef3f15023b",
            "49578c2e2c67463a8f0d56ce7640a98a",
            "e38e145ef286450bad092aaca7f3eca3",
            "2a10c9454ee24826bf8effbb8c2ab4e0",
            "bae4af88e77e40109181dfb571e020a8",
            "aef567bb2e804315a87e415196bb5e41",
            "889533cd9e78476a9738c7d0e761c395",
            "aecdedbce862434184f48078661551dc",
            "85daddacda0b46239d7b4cb47d3f27ff",
            "7ec035a4d46f4b24b8b9d621dfe6fe2b",
            "6e0b56619442495d84371a2efdd20996",
            "9aaa152b53f44d0b8724bce7b7922fd7",
            "1a486f5aefa54d8f9a4597d690d47d16",
            "a325aba323f44befa35194d438eaf4d2",
            "f5a2a8723be34b889fb1ae63d85b3af3",
            "18d53218c50c41118f7aea700af1f964",
            "25b492c8da4841e981b1a8cb9dcdc184",
            "ae5bab07f95048db9bcb4fade9c3f7c1",
            "fd00f7a67ce446e19ba382c61cd75262",
            "850eeb863d834fca84f14a722cfa322d",
            "21b35a3a4e4f429b9f9cd3ea6a725a52",
            "eb38aecae9ba4539abbb60db201a47b1",
            "4972e60638c748c1a144a07a23695f47",
            "7f418bcd26de4d2390103f806460ae96",
            "9a1e91a7312c448aae07d5c4f2b31a22",
            "dc8148ff86a4405d8421fcb2a0dea0a4",
            "4e6df5d2d939487e909d09f4d855d4e7",
            "06636fa4fdb2438b8d0d4aeaade43e7a",
            "6726e1b328e24fe29bb6158d6ae03f1f",
            "c5880bb5e5474742b9085886bec05753"
          ]
        },
        "id": "-xHJjNvJ-YOp",
        "outputId": "2b6b7d61-7755-47b0-c4a5-b7ec1d82a9f8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "047e4f5bb8634f1ea706e06f376fef7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a92aa0db5a346329c02079b2ec30501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85daddacda0b46239d7b4cb47d3f27ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "850eeb863d834fca84f14a722cfa322d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzer specialist tool\n",
        "class EarningsAnalyzer:\n",
        "    def __init__(self, yahoo_tool, sec_tool):\n",
        "        self.yahoo_tool = yahoo_tool\n",
        "        self.sec_tool = sec_tool\n",
        "\n",
        "    def analyze(self, symbol, messages=None):\n",
        "        # 1. Try to find earnings info in past messages\n",
        "        yahoo_data = None\n",
        "        if messages:\n",
        "            for msg in reversed(messages):\n",
        "                # ToolMessage expected structure\n",
        "                # Check by tool name and relevant symbol\n",
        "                if (\n",
        "                    hasattr(msg, \"name\") and msg.name == \"YahooFinanceAPI\"\n",
        "                    and hasattr(msg, \"content\") and symbol in msg.content\n",
        "                ):\n",
        "                    yahoo_data = msg.content  # or parse accordingly\n",
        "                    break\n",
        "        # 2. If not found, call API\n",
        "        if yahoo_data is None:\n",
        "            yahoo_data = self.yahoo_tool.fetch_earnings(symbol)\n",
        "        # ... do similar for sec filings ...\n",
        "        # 3. Build and return your summary\n",
        "        return f\"Analysis based on earnings: {yahoo_data}\"\n",
        "\n",
        "earnings_specialist = Tool(\n",
        "    name=\"EarningsAnalyzer\",\n",
        "    func=lambda symbol, messages: EarningsAnalyzer(yahoo_api_tool, sec_api_tool).analyze(symbol, messages=messages),\n",
        "    description=\"Expert analysis of earnings via Yahoo Finance and SEC filings\"\n",
        ")"
      ],
      "metadata": {
        "id": "DktVl60f8pk1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalyzer:\n",
        "    def __init__(self, sentiment_tool, news_tool):\n",
        "        self.sentiment_tool = sentiment_tool  # expects .analyze(text)\n",
        "        self.news_tool = news_tool            # expects .get_news(symbol)\n",
        "\n",
        "    def analyze(self, symbol, messages=None):\n",
        "        # 1. Find any recent news/sentiment in agent messages\n",
        "        headlines = []\n",
        "        if messages:\n",
        "            for msg in reversed(messages):\n",
        "                # If you have ToolMessage for news and symbol in content\n",
        "                if hasattr(msg, \"name\") and msg.name in [\"NewsAPI\", \"TavilyNewsSearch\"]:\n",
        "                    if hasattr(msg, \"content\") and symbol in msg.content:\n",
        "                        # Try splitting headlines (change this parsing as needed)\n",
        "                        headlines += msg.content.split(\"\\n\")\n",
        "                # If you cache sentiment scores/results, you can parse those too!\n",
        "\n",
        "        # 2. If no headlines found, call news API/tool\n",
        "        if not headlines:\n",
        "            news_items = self.news_tool.get_news(symbol)\n",
        "            headlines = [item['headline'] for item in news_items]\n",
        "\n",
        "        # 3. Get sentiment scores for each headline\n",
        "        if headlines:\n",
        "            scores = [self.sentiment_tool.analyze(h) for h in headlines]\n",
        "            if scores:\n",
        "                mean_score = sum(scores) / len(scores)\n",
        "                recommendation = self._interpret_score(mean_score)\n",
        "                return (f\"Average news sentiment for {symbol}: {mean_score:.2f}\\n\"\n",
        "                        f\"Recommendation: {recommendation}\")\n",
        "            else:\n",
        "                return \"No sentiment scores could be computed.\"\n",
        "        else:\n",
        "            return \"No recent news headlines found.\"\n",
        "\n",
        "    def _interpret_score(self, score):\n",
        "        # Customize thresholds to your model's scoring scale\n",
        "        if score > 0.2:\n",
        "            return \"Buy\"\n",
        "        elif score > -0.2:\n",
        "            return \"Hold\"\n",
        "        else:\n",
        "            return \"Sell\"\n",
        "\n",
        "sentiment_anaylsis_specialist = Tool(\n",
        "    name=\"SentimentAnalyzer\",\n",
        "    func=lambda symbol, messages: SentimentAnalyzer(sentiment_api_tool, news_api_tool).analyze(symbol, messages=messages),\n",
        "    description=\"Aggregates news sentiment for a stock and suggests buy/hold/sell.\"\n",
        ")"
      ],
      "metadata": {
        "id": "hZmML2_R-IQl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simpler way to create tool?\n",
        "#def get_weather(city: str) -> str:\n",
        "#    \"\"\"Get weather for a given city.\"\"\"\n",
        "#    return f\"It's always sunny in {city}!\""
      ],
      "metadata": {
        "id": "LEzyYI30599E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "biMVj3ifg3ha"
      },
      "outputs": [],
      "source": [
        "#Create the tools list\n",
        "tools = [\n",
        "    yahoo_api_tool,\n",
        "    sec_api_tool,\n",
        "    news_api_tool,\n",
        "    tavily_news_tool,\n",
        "    wikipedia_tool,\n",
        "    sentiment_api_tool,\n",
        "    earnings_specialist,\n",
        "    sentiment_anaylsis_specialist,\n",
        "    wikipedia_tool\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "tools_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"symbol\", \"company_name\", \"date\", \"agent_scratchpad\", \"research_notes\"],\n",
        "    template=\"\"\"You are an autonomous investment research agent.\n",
        "Today's Date: {date}\n",
        "User Input: {input}\n",
        "Stock Symbol: {symbol}\n",
        "\n",
        "Company: {company_name}\n",
        "Scratchpad: {agent_scratchpad}\n",
        "Research Notes: {research_notes}\n",
        "\n",
        "You are an autonomous investment research agent.\n",
        "Instructions:\n",
        "1. Identify the relevant stock symbol for {input}. If {symbol} is not provided, use the tools or reasoning to determine it from the company name.\n",
        "2. Plan your research steps dynamically for {input} ({symbol}) (select relevant data & order).\n",
        "3. Use available tools for financials, news, and economics as required.\n",
        "4. Route to specialist modules (earnings, market sentiment, news) when appropriate.\n",
        "5. Evaluate your results and refine if necessary to improve analysis quality.\n",
        "6. Save lessons or notes in research_notes for future runs.\n",
        "Output a complete investment report with evidence and recommendations.\n",
        "\n",
        "{agent_scratchpad}\n",
        "Persistent notes: {research_notes}\n",
        "\n",
        "Start your workflow:\n",
        "\n",
        "\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "lMvCRDW_7EjS"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_EbjC2ok3m4"
      },
      "source": [
        "### Tools Agent Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "wyMhkBfhf3Hi"
      },
      "outputs": [],
      "source": [
        "tools_agent = create_react_agent(\n",
        "    model=llm_openai,\n",
        "    tools=tools,\n",
        "    prompt=prompt=\"You are a financial research agent. Analyze the user's request and use your tools to gather information.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For testing\n",
        "#Example:\n",
        "#tools_output = tools_agent.invoke({\"messages\": [{'role': 'user', 'content': 'Research TSLA'}]})\n",
        "#print(result)"
      ],
      "metadata": {
        "id": "iKVq1h3jfdap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987QsT47jjIH"
      },
      "source": [
        "## Self Reflection & Evaluation Agent\n",
        "Evaluates output quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "hKhXB6THg4Ua"
      },
      "outputs": [],
      "source": [
        "# Define Self Evaluation agent\n",
        "\n",
        "EVAL_PROMPT = \"\"\"\n",
        "You are an expert evaluator. Ensure the result is no more than 100 words and is formatted for easy reading including bulleted lists, and a clear title at the top.\n",
        "\n",
        "In addition, review the analysis/summary below for:\n",
        "\n",
        "- Completeness (all important steps/points covered)\n",
        "- Succinctness (concise, minimal repetition)\n",
        "- Accuracy (supported by real or tool-sourced information)\n",
        "- Clarity (well organized, easy to follow)\n",
        "\n",
        "If human feedback is provided, incorporate any specific suggestions or corrections if appropriate.\n",
        "\n",
        "Give clear, specific suggestions if any improvement is needed.\n",
        "Return the revised summary/answer if changes are warranted.\n",
        "Otherwise, state that the answer is adequate.\n",
        "\n",
        "--- Analysis To Evaluate ---\n",
        "{input}\n",
        "\n",
        "--- Human Feedback ---\n",
        "{human_feedback}\n",
        "\"\"\"\n",
        "\n",
        "evaluator_agent = create_react_agent(\n",
        "    model=llm_openai, # Or gemini_model if that's your variable\n",
        "    tools = [],\n",
        "    prompt=EVAL_PROMPT\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run for testing\n",
        "#evaluator_output = self_evaluator.invoke({\"input\": tools_output})\n",
        "#print(evaluator_output)"
      ],
      "metadata": {
        "id": "4sJkRiJNWrMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOBnNHeJl3r-"
      },
      "source": [
        "## Optimization Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "eqo6xLUkltoO"
      },
      "outputs": [],
      "source": [
        "# Define optimizer agent\n",
        "\n",
        "OPTIMIZER_PROMPT = \"\"\"\n",
        "You are an optimization agent. Given the evaluator's feedback and the initial summary below,\n",
        "produce a revised version that fixes any weaknesses cited (completeness, succinctness, accuracy, clarity).\n",
        "Ensure the answer is relevant, including the stock symobl and data retrieved.\n",
        "\n",
        "Limit response to 100 words with a simple bulleted format for key info like stock symobl, company name, today's date, etc.. Only write what you have found, don't make anything up.\n",
        "\n",
        "Evaluator Feedback:\n",
        "{feedback}\n",
        "Initial Answer:\n",
        "{answer}\n",
        "\n",
        "---\n",
        "Optimized Revised Answer:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "optimizer_agent = create_react_agent(\n",
        "    model=llm_openai, # Or gemini_model if that's your variable\n",
        "    tools = [],\n",
        "    prompt=OPTIMIZER_PROMPT\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For testing\n",
        "#answer = tools_output\n",
        "#feedback = evaluator_output\n",
        "#print(answer)\n",
        "#print(feedback)\n",
        "#optimized_result = optimizer_agent.invoke({\n",
        "#    \"answer\": answer,\n",
        "#    \"feedback\": feedback\n",
        "#})\n",
        "#print(optimized_result)"
      ],
      "metadata": {
        "id": "ym4SMlKTXT0z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_CeRDyhjmUp"
      },
      "source": [
        "## Learning Agent\n",
        "Maintains memory across analysis runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "l_7UNagLGt60"
      },
      "outputs": [],
      "source": [
        "#MEMORY AGENT CELL 1\n",
        "#Session-scoped memory\n",
        "\n",
        "@dataclass\n",
        "class MemoryItem:\n",
        "    symbol: str\n",
        "    question: str\n",
        "    answer: str\n",
        "    created_at: str\n",
        "    meta: Dict[str, Any]\n",
        "\n",
        "class SessionMemory:\n",
        "    def __init__(self, max_items: int = 200, max_per_symbol: int = 10):\n",
        "        self._store: Dict[str, List[MemoryItem]] = {}\n",
        "        self.max_items = max_items\n",
        "        self.max_per_symbol = max_per_symbol\n",
        "\n",
        "    def remember(self, symbol: str, question: str, answer: str, **meta) -> None:\n",
        "        symbol = (symbol or \"GENERIC\").upper().strip()\n",
        "        item = MemoryItem(\n",
        "            symbol=symbol,\n",
        "            question=(question or \"\").strip(),\n",
        "            answer=(answer or \"\").strip(),\n",
        "            created_at=datetime.utcnow().isoformat(timespec=\"seconds\"),\n",
        "            meta=meta or {}\n",
        "        )\n",
        "        bucket = self._store.setdefault(symbol, [])\n",
        "        bucket.append(item)\n",
        "        if len(bucket) > self.max_per_symbol:\n",
        "            del bucket[0 : len(bucket) - self.max_per_symbol]\n",
        "        self._cap_global()\n",
        "\n",
        "    def recall(self, symbol: str, question: Optional[str] = None) -> Optional[str]:\n",
        "        symbol = (symbol or \"GENERIC\").upper().strip()\n",
        "        bucket = self._store.get(symbol, [])\n",
        "        if not bucket:\n",
        "            return None\n",
        "        if not question:\n",
        "            return bucket[-1].answer\n",
        "        q = (question or \"\").strip()\n",
        "        for item in reversed(bucket):\n",
        "            if item.question == q:\n",
        "                return item.answer\n",
        "        return None\n",
        "\n",
        "    def latest(self, symbol: str) -> Optional[MemoryItem]:\n",
        "        symbol = (symbol or \"GENERIC\").upper().strip()\n",
        "        bucket = self._store.get(symbol, [])\n",
        "        return bucket[-1] if bucket else None\n",
        "\n",
        "    def _cap_global(self):\n",
        "        all_items = []\n",
        "        for sym, bucket in self._store.items():\n",
        "            for it in bucket:\n",
        "                all_items.append((it.created_at, sym, it))\n",
        "        if len(all_items) <= self.max_items:\n",
        "            return\n",
        "        all_items.sort(key=lambda x: x[0])  # oldest first\n",
        "        to_drop = len(all_items) - self.max_items\n",
        "        cutoff = set(id(it) for _, _, it in all_items[:to_drop])\n",
        "        for sym in list(self._store.keys()):\n",
        "            self._store[sym] = [it for it in self._store[sym] if id(it) not in cutoff]\n",
        "\n",
        "SESSION_MEMORY = SessionMemory()\n",
        "\n",
        "def extract_symbol(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Grab a likely ticker from the user_input like 'Analyze the SPY stock ticker'.\n",
        "    Simple heuristic: first ALL-CAPS token 1-5 chars (e.g., AAPL, MSFT, SPY).\n",
        "    Falls back to 'GENERIC' if none found.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"GENERIC\"\n",
        "    candidates = re.findall(r\"\\b[A-Z]{1,5}\\b\", text)\n",
        "    # Light filter for common English words\n",
        "    stop = {\"THE\",\"AND\",\"FOR\",\"WITH\",\"FROM\",\"THIS\",\"THAT\",\"YOUR\",\"HAVE\",\"HOLD\"}\n",
        "    for c in candidates:\n",
        "        if c not in stop:\n",
        "            return c\n",
        "    return \"GENERIC\"\n",
        "\n",
        "def as_text(x: Any) -> str:\n",
        "    \"\"\"\n",
        "    Normalize whatever comes back from planner/tools/evaluator/optimizer into a string.\n",
        "    Works with LangChain AgentExecutor outputs (dict), AIMessage, or raw str.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # AIMessage / ChatMessage\n",
        "        if hasattr(x, \"content\"):\n",
        "            return str(x.content)\n",
        "        # Agent-like dicts\n",
        "        if isinstance(x, dict):\n",
        "            if \"output\" in x and isinstance(x[\"output\"], str):\n",
        "                return x[\"output\"]\n",
        "            if \"messages\" in x and isinstance(x[\"messages\"], list):\n",
        "                return \"\\n\\n\".join(\n",
        "                    (m.content if hasattr(m, \"content\") else str(m))\n",
        "                    for m in x[\"messages\"]\n",
        "                )\n",
        "        # plain string\n",
        "        if isinstance(x, str):\n",
        "            return x\n",
        "        return str(x)\n",
        "    except Exception:\n",
        "        return str(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPxekd7Rj2KW"
      },
      "source": [
        "## Multiple Agent Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "3TH58wPz7RHV"
      },
      "outputs": [],
      "source": [
        "user_input = \"Analyze the AAPL stock\" #Example user input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Start with a simple state dictionary\n",
        "def create_initial_state(user_input):\n",
        "    return {\n",
        "        \"user_input\": user_input,\n",
        "        \"symbol\": extract_symbol_simple(user_input),  # Simple regex\n",
        "        \"date\": datetime.now().date().isoformat(),\n",
        "        \"tools_output\": \"\",\n",
        "        \"evaluation_output\": \"\",\n",
        "        \"final_output\": \"\"\n",
        "    }\n",
        "\n",
        "def extract_symbol_simple(text):\n",
        "    \"\"\"Just grab first 2-5 char uppercase word\"\"\"\n",
        "    match = re.search(r\"\\b([A-Z]{2,5})\\b\", text)\n",
        "    return match.group(1) if match else \"UNKNOWN\"\n",
        "\n",
        "# 2. Simple agent creation - let the agent handle its own prompting\n",
        "tools_agent = create_react_agent(\n",
        "    model=llm_openai,\n",
        "    tools=tools,\n",
        "    # Use a simple string prompt, not a template\n",
        "    prompt=\"You are a financial research agent. Analyze the user's request and use your tools to gather information.\"\n",
        ")\n",
        "\n",
        "# 3. Simplified execution pipeline\n",
        "def run_analysis_pipeline(user_input):\n",
        "    # Create state\n",
        "    state = create_initial_state(user_input)\n",
        "    print(f\"Analyzing: {user_input}\")\n",
        "    print(f\"Symbol: {state['symbol']}\")\n",
        "\n",
        "    # Tools agent - pass the user input directly\n",
        "    try:\n",
        "        tools_result = tools_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
        "        state[\"tools_output\"] = str(tools_result)\n",
        "        print(\"✓ Tools agent completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Tools agent failed: {e}\")\n",
        "        return state\n",
        "\n",
        "    # Evaluator agent\n",
        "    try:\n",
        "        eval_result = evaluator_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": f\"Evaluate this analysis: {state['tools_output']}\"}]})\n",
        "        state[\"evaluation_output\"] = str(eval_result)\n",
        "        print(\"✓ Evaluator completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Evaluator failed: {e}\")\n",
        "        return state\n",
        "\n",
        "    # Optimizer agent\n",
        "    try:\n",
        "        optimizer_result = optimizer_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": f\"Optimize this analysis based on evaluation:\\nAnalysis: {state['tools_output']}\\nEvaluation: {state['evaluation_output']}\"}]})\n",
        "        state[\"final_output\"] = str(optimizer_result)\n",
        "        print(\"✓ Optimizer completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Optimizer failed: {e}\")\n",
        "        return state\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "k_vu8fN56tl3"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute code above\n",
        "result = run_analysis_pipeline(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TVp_hxz61MU",
        "outputId": "bdf98794-3628-4244-90e0-c04062012001"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing: Analyze the AAPL stock\n",
            "Symbol: AAPL\n",
            "cik_resp: 200, {\"0\":{\"cik_str\":1045810,\"ticker\":\"NVDA\",\"title\":\"NVIDIA CORP\"},\"1\":{\"cik_str\":789019,\"ticker\":\"MSFT\"\n",
            "✓ Tools agent completed\n",
            "✓ Evaluator completed\n",
            "✓ Optimizer completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77TtDwYXq2A_",
        "outputId": "d27a02ce-03fb-4e4f-fa95-83b247b0ff9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating user input...\n",
            "{'input': 'Analyze the AAPL stock', 'symbol': 'AAPL', 'company_name': '', 'date': '2025-10-06', 'agent_scratchpad': '', 'research_notes': ''}\n",
            "Tools Agent Reasoning...\n",
            "Tools Agent Exception: <class 'KeyError'> \"Input to PromptTemplate is missing variables {'research_notes', 'agent_scratchpad', 'input', 'symbol'}.  Expected: ['agent_scratchpad', 'input', 'research_notes', 'symbol'] Received: ['messages', 'remaining_steps']\\nNote: if you intended {research_notes} to be part of the string and not a variable, please escape it with double curly braces like: '{{research_notes}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"\n",
            "\n",
            "Evaluator Agent Reasoning...\n",
            "Evaluator Agent Output: {'messages': [AIMessage(content='### Evaluation of Analysis on Evaluating a Business Idea\\n\\nThe analysis provided a comprehensive guide on evaluating a business idea, covering key steps such as market research, identifying target customers, assessing competition, analyzing costs, and testing the idea. The information was concise and accurate, offering a clear and organized approach. To enhance clarity, consider breaking down complex steps into simpler sub-steps and providing examples or tools for each stage. Additionally, incorporating real-world case studies could further illustrate the evaluation process. Overall, the analysis is adequate but could benefit from more practical examples and detailed explanations.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 161, 'total_tokens': 275, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CNXLTG0QoKmU11cwNjN6kO5WSHnLy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c2efcd06-a0f4-4a88-a6ec-08e029ae9f18-0', usage_metadata={'input_tokens': 161, 'output_tokens': 114, 'total_tokens': 275, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\n",
            "Optimizer Agent Reasoning...\n",
            "\n",
            "Raw optimizer_output:\n",
            "{'messages': [AIMessage(content='- Stock Symbol: AAPL\\n- Company Name: Apple Inc.\\n- Date: October 15, 2021\\n- Closing Price: $143.76', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 121, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CNXLU9fhEbHNnqzgyRePpmVMfv4E5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b0128005-324e-4023-ac21-b2cbf936a075-0', usage_metadata={'input_tokens': 121, 'output_tokens': 33, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\n",
            "---\n",
            "\n",
            "Message 1 content:\n",
            "\n",
            "- Stock Symbol: AAPL\n",
            "- Company Name: Apple Inc.\n",
            "- Date: October 15, 2021\n",
            "- Closing Price: $143.76\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating user input...\")\n",
        "\n",
        "# Run the context extraction function directly\n",
        "context_output = extract_context(user_input)\n",
        "print(context_output)\n",
        "\n",
        "#Tools Agent\n",
        "print(\"Tools Agent Reasoning...\")\n",
        "\n",
        "\n",
        "try:\n",
        "    tools_output = tools_agent.invoke(context_output)\n",
        "    print(\"Tools Agent Output:\", tools_output)\n",
        "except Exception as e:\n",
        "    print(\"Tools Agent Exception:\", type(e), e)\n",
        "print()\n",
        "\n",
        "#Evaluator Agent\n",
        "print(\"Evaluator Agent Reasoning...\")\n",
        "evaluation_output = self_evaluator.invoke({\"input\": tools_output})\n",
        "print(\"Evaluator Agent Output:\", evaluation_output)\n",
        "print()\n",
        "\n",
        "#Optimizer Agent\n",
        "print(\"Optimizer Agent Reasoning...\")\n",
        "optimizer_input = {\n",
        "    \"tools_output\": tools_output,\n",
        "    \"evaluation_output\": evaluation_output\n",
        "}\n",
        "optimizer_output = optimizer_agent.invoke(optimizer_input)\n",
        "print()\n",
        "\n",
        "def print_optimizer_output(optimizer_output):\n",
        "    print(\"Raw optimizer_output:\")\n",
        "    print(optimizer_output)\n",
        "    print(\"\\n---\\n\")\n",
        "\n",
        "    if isinstance(optimizer_output, str):\n",
        "        for para in optimizer_output.split('\\n\\n'):\n",
        "            print(para)\n",
        "            print()\n",
        "    elif isinstance(optimizer_output, dict):\n",
        "        # Check if 'messages' is present and is a list of message objects\n",
        "        if \"messages\" in optimizer_output:\n",
        "            messages = optimizer_output[\"messages\"]\n",
        "            for idx, msg in enumerate(messages):\n",
        "                # Handles AIMessage or generic object with .content\n",
        "                try:\n",
        "                    content = msg.content\n",
        "                except AttributeError:\n",
        "                    content = str(msg)\n",
        "                print(f\"Message {idx+1} content:\\n\")\n",
        "                for para in content.split('\\n\\n'):\n",
        "                    print(para)\n",
        "                    print()\n",
        "        else:\n",
        "            print(\"optimizer_output is a dict but no 'messages' key found. Printing dict keys/values:\")\n",
        "            for k, v in optimizer_output.items():\n",
        "                print(f\"{k}: {v}\\n\")\n",
        "    else:\n",
        "        print(\"optimizer_output type could not be handled:\")\n",
        "        print(type(optimizer_output))\n",
        "\n",
        "# Usage:\n",
        "print_optimizer_output(optimizer_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After running the user query through your whole pipeline:\n",
        "user_question = user_input\n",
        "symbol = extract_symbol(user_input)\n",
        "final_answer = as_text(optimizer_output)   # Use your utility function\n",
        "\n",
        "SESSION_MEMORY.remember(symbol, user_question, final_answer)\n",
        "\n",
        "# Later, you can recall the latest answer for \"AAPL\":\n",
        "prev = SESSION_MEMORY.recall(\"AAPL\")\n",
        "if prev:\n",
        "    print(\"Previous answer for AAPL:\", prev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTu73fn72wD3",
        "outputId": "83c1a02e-0733-42c7-d8da-278c49169fe8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous answer for AAPL: - Stock Symbol: AAPL\n",
            "- Company Name: Apple Inc.\n",
            "- Date: October 15, 2021\n",
            "- Closing Price: $143.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3075633432.py:24: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  created_at=datetime.utcnow().isoformat(timespec=\"seconds\"),\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KOBnNHeJl3r-",
        "n_CeRDyhjmUp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "047e4f5bb8634f1ea706e06f376fef7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc143309bac14465b28197b3d7216b88",
              "IPY_MODEL_ae36bf92882b4b898c4e790f6816644f",
              "IPY_MODEL_c270447b325a4669b7206c5277825728"
            ],
            "layout": "IPY_MODEL_0924a3a6bb6745ed832196b5ac1735c2"
          }
        },
        "bc143309bac14465b28197b3d7216b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c8c80896584df68ebc192d2d270d0f",
            "placeholder": "​",
            "style": "IPY_MODEL_93704669bbc04d16b559aaa7ca038b85",
            "value": "config.json: 100%"
          }
        },
        "ae36bf92882b4b898c4e790f6816644f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_151fadcd660b4ba6aa4b689ea0911a64",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61e0505a3457467ba2ab7b76c0d614f0",
            "value": 629
          }
        },
        "c270447b325a4669b7206c5277825728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c028f7bbbf77493dbc5161390077f320",
            "placeholder": "​",
            "style": "IPY_MODEL_2bf0fbcc900c47629b595382255d4d1b",
            "value": " 629/629 [00:00&lt;00:00, 46.1kB/s]"
          }
        },
        "0924a3a6bb6745ed832196b5ac1735c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c8c80896584df68ebc192d2d270d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93704669bbc04d16b559aaa7ca038b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "151fadcd660b4ba6aa4b689ea0911a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e0505a3457467ba2ab7b76c0d614f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c028f7bbbf77493dbc5161390077f320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf0fbcc900c47629b595382255d4d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a92aa0db5a346329c02079b2ec30501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73aa0b6b4ada48a98c4c88730aa70452",
              "IPY_MODEL_f1b7a0cbd27b4bc5b5a71808e6f9c777",
              "IPY_MODEL_65945c21c7d34dcbb58e66ef3f15023b"
            ],
            "layout": "IPY_MODEL_49578c2e2c67463a8f0d56ce7640a98a"
          }
        },
        "73aa0b6b4ada48a98c4c88730aa70452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38e145ef286450bad092aaca7f3eca3",
            "placeholder": "​",
            "style": "IPY_MODEL_2a10c9454ee24826bf8effbb8c2ab4e0",
            "value": "model.safetensors: 100%"
          }
        },
        "f1b7a0cbd27b4bc5b5a71808e6f9c777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae4af88e77e40109181dfb571e020a8",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aef567bb2e804315a87e415196bb5e41",
            "value": 267832558
          }
        },
        "65945c21c7d34dcbb58e66ef3f15023b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889533cd9e78476a9738c7d0e761c395",
            "placeholder": "​",
            "style": "IPY_MODEL_aecdedbce862434184f48078661551dc",
            "value": " 268M/268M [00:10&lt;00:00, 25.8MB/s]"
          }
        },
        "49578c2e2c67463a8f0d56ce7640a98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38e145ef286450bad092aaca7f3eca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a10c9454ee24826bf8effbb8c2ab4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bae4af88e77e40109181dfb571e020a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef567bb2e804315a87e415196bb5e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "889533cd9e78476a9738c7d0e761c395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aecdedbce862434184f48078661551dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85daddacda0b46239d7b4cb47d3f27ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ec035a4d46f4b24b8b9d621dfe6fe2b",
              "IPY_MODEL_6e0b56619442495d84371a2efdd20996",
              "IPY_MODEL_9aaa152b53f44d0b8724bce7b7922fd7"
            ],
            "layout": "IPY_MODEL_1a486f5aefa54d8f9a4597d690d47d16"
          }
        },
        "7ec035a4d46f4b24b8b9d621dfe6fe2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a325aba323f44befa35194d438eaf4d2",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a2a8723be34b889fb1ae63d85b3af3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6e0b56619442495d84371a2efdd20996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d53218c50c41118f7aea700af1f964",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25b492c8da4841e981b1a8cb9dcdc184",
            "value": 48
          }
        },
        "9aaa152b53f44d0b8724bce7b7922fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae5bab07f95048db9bcb4fade9c3f7c1",
            "placeholder": "​",
            "style": "IPY_MODEL_fd00f7a67ce446e19ba382c61cd75262",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.56kB/s]"
          }
        },
        "1a486f5aefa54d8f9a4597d690d47d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a325aba323f44befa35194d438eaf4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a2a8723be34b889fb1ae63d85b3af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18d53218c50c41118f7aea700af1f964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b492c8da4841e981b1a8cb9dcdc184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae5bab07f95048db9bcb4fade9c3f7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd00f7a67ce446e19ba382c61cd75262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "850eeb863d834fca84f14a722cfa322d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21b35a3a4e4f429b9f9cd3ea6a725a52",
              "IPY_MODEL_eb38aecae9ba4539abbb60db201a47b1",
              "IPY_MODEL_4972e60638c748c1a144a07a23695f47"
            ],
            "layout": "IPY_MODEL_7f418bcd26de4d2390103f806460ae96"
          }
        },
        "21b35a3a4e4f429b9f9cd3ea6a725a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1e91a7312c448aae07d5c4f2b31a22",
            "placeholder": "​",
            "style": "IPY_MODEL_dc8148ff86a4405d8421fcb2a0dea0a4",
            "value": "vocab.txt: "
          }
        },
        "eb38aecae9ba4539abbb60db201a47b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6df5d2d939487e909d09f4d855d4e7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06636fa4fdb2438b8d0d4aeaade43e7a",
            "value": 1
          }
        },
        "4972e60638c748c1a144a07a23695f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6726e1b328e24fe29bb6158d6ae03f1f",
            "placeholder": "​",
            "style": "IPY_MODEL_c5880bb5e5474742b9085886bec05753",
            "value": " 232k/? [00:00&lt;00:00, 9.27MB/s]"
          }
        },
        "7f418bcd26de4d2390103f806460ae96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1e91a7312c448aae07d5c4f2b31a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8148ff86a4405d8421fcb2a0dea0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e6df5d2d939487e909d09f4d855d4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "06636fa4fdb2438b8d0d4aeaade43e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6726e1b328e24fe29bb6158d6ae03f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5880bb5e5474742b9085886bec05753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}